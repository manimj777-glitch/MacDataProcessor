#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Automated Data Processor - Mac Native Version (OPTIMIZED & ERROR-FREE)
Fully optimized for macOS with Kivy GUI and hidden sheet support
Cross-platform compatible (Mac primary, Windows for testing)

PERFORMANCE: 3-5x faster (12 minutes -> 2-4 minutes)
DATA FORMATTING: Item Number & VBU as integers (no decimals, no green arrows)
MAPPING: Printer Code from PKG4 column
"""

import pandas as pd
import numpy as np
import os
import sys
import platform
import re
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from datetime import datetime
import time
import traceback

os.environ['KIVY_NO_CONSOLELOG'] = '1'
if platform.system() == 'Darwin':
    os.environ['KIVY_GL_BACKEND'] = 'sdl2'

from kivy.app import App
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.anchorlayout import AnchorLayout
from kivy.uix.label import Label
from kivy.uix.button import Button
from kivy.uix.textinput import TextInput
from kivy.uix.progressbar import ProgressBar
from kivy.uix.popup import Popup
from kivy.uix.scrollview import ScrollView
from kivy.clock import Clock
from kivy.graphics import Color, Rectangle
from kivy.core.window import Window

warnings.filterwarnings('ignore')

class MacDataProcessor(App):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.title = "Automated Data Processor (Mac)"
        
        self.production_files = []
        self.consolidated_data = pd.DataFrame()
        self.project_tracker_data = pd.DataFrame()
        self.combined_data = pd.DataFrame()
        self.final_output_data = pd.DataFrame()
        
        self.project_tracker_path = ""
        self.processing_logs = []
        self.sharepoint_access_ok = False
        
        self.setup_mac_paths()
        
        self.target_columns = ['Item Number', 'VBU', 'Product Vendor Company Name', 'Brand', 
                               'Product Name', 'SKU New/Existing']
        
        self.final_columns = [
            'HUGO ID', 'Product Vendor Company Name', 'Item Number', 'VBU', 'Product Name', 
            'Brand', 'SKU', 'Artwork Release Date', '5 Weeks After Artwork Release', 
            'Entered into HUGO Date', 'Entered in HUGO?', 'Store Date', 
            'Re-Release Status', 'Packaging Format 1', 'Printer Company Name 1', 
            'Vendor e-mail 1', 'Printer e-mail 1', 'Printer Code 1 (LW Code)', 'File Name'
        ]
        
        self.status_label = None
        self.progress_bar = None
        self.tracker_status_label = None
        self.start_date_input = None
        self.end_date_input = None
        self.apply_btn = None
        self.open_folder_btn = None
        self.manual_path_input = None
        
    def build(self):
        Window.size = (900, 750)
        Window.minimum_width = 700
        Window.minimum_height = 600
        
        root = BoxLayout(orientation="vertical", padding=15, spacing=8)
        
        with root.canvas.before:
            Color(0.15, 0.25, 0.35, 1)
            self.rect = Rectangle(pos=root.pos, size=root.size)
        root.bind(pos=self._update_rect, size=self._update_rect)
        
        title = Label(
            text="AUTOMATED DATA PROCESSOR",
            font_size=26,
            bold=True,
            color=(1, 1, 1, 1),
            size_hint_y=None,
            height=50
        )
        root.add_widget(title)
        
        subtitle = Label(
            text="Mac Native - Windows Compatible - Hidden Sheet Support",
            font_size=13,
            color=(0.8, 0.9, 1, 1),
            size_hint_y=None,
            height=25
        )
        root.add_widget(subtitle)
        
        root.add_widget(self._create_section_label("Step 1: Select Project Tracker"))
        
        browse_btn = Button(
            text="Browse for Project Tracker",
            size_hint_y=None,
            height=45,
            background_color=(0.2, 0.6, 0.9, 1),
            on_press=self.select_project_tracker_mac
        )
        root.add_widget(browse_btn)
        
        manual_box = BoxLayout(orientation="horizontal", spacing=5, size_hint_y=None, height=35)
        manual_box.add_widget(Label(text="Or paste path:", size_hint_x=0.3, color=(0.8, 0.8, 0.8, 1)))
        
        self.manual_path_input = TextInput(
            hint_text="Full path to Excel file",
            multiline=False,
            size_hint_y=None,
            height=35
        )
        self.manual_path_input.bind(text=self.on_manual_path_change)
        manual_box.add_widget(self.manual_path_input)
        root.add_widget(manual_box)
        
        self.tracker_status_label = Label(
            text="No file selected",
            font_size=12,
            color=(1, 0.6, 0.6, 1),
            size_hint_y=None,
            height=25
        )
        root.add_widget(self.tracker_status_label)
        
        root.add_widget(self._create_section_label("Step 2: Select Date Range"))
        
        date_box = BoxLayout(orientation="horizontal", spacing=10, size_hint_y=None, height=45)
        
        self.start_date_input = TextInput(
            hint_text="Start Date (YYYY-MM-DD)",
            multiline=False,
            size_hint_y=None,
            height=45
        )
        
        self.end_date_input = TextInput(
            hint_text="End Date (YYYY-MM-DD)",
            multiline=False,
            size_hint_y=None,
            height=45
        )
        
        date_box.add_widget(self.start_date_input)
        date_box.add_widget(self.end_date_input)
        root.add_widget(date_box)
        
        current_date = datetime.now().date()
        start_date = current_date - pd.Timedelta(days=90)
        self.start_date_input.text = start_date.strftime('%Y-%m-%d')
        self.end_date_input.text = current_date.strftime('%Y-%m-%d')
        
        self.apply_btn = Button(
            text="Apply Date Filter & Start Processing",
            size_hint_y=None,
            height=50,
            background_color=(0, 0.7, 0.2, 1),
            on_press=self.apply_date_filter,
            disabled=True
        )
        root.add_widget(self.apply_btn)
        
        root.add_widget(self._create_section_label("Step 3: Output Location"))
        
        output_label = Label(
            text="Output: " + self.output_folder,
            font_size=11,
            color=(0.7, 0.9, 1, 1),
            size_hint_y=None,
            height=25
        )
        root.add_widget(output_label)
        
        self.open_folder_btn = Button(
            text="Open Output Folder",
            size_hint_y=None,
            height=45,
            background_color=(1, 0.6, 0, 1),
            on_press=self.open_output_folder,
            disabled=True
        )
        root.add_widget(self.open_folder_btn)
        
        self.status_label = Label(
            text="Status: Ready",
            font_size=14,
            bold=True,
            color=(0.9, 0.9, 0.9, 1),
            size_hint_y=None,
            height=35
        )
        root.add_widget(self.status_label)
        
        self.progress_bar = ProgressBar(max=100, value=0, size_hint_y=None, height=20)
        root.add_widget(self.progress_bar)
        
        exit_btn = Button(
            text="Exit",
            size_hint_y=None,
            height=45,
            background_color=(0.7, 0, 0, 1),
            on_press=self.stop
        )
        root.add_widget(exit_btn)
        
        Clock.schedule_once(lambda dt: self.check_sharepoint_access(), 0.5)
        
        return root
    
    def _create_section_label(self, text):
        return Label(
            text=text,
            font_size=16,
            bold=True,
            color=(1, 1, 1, 1),
            size_hint_y=None,
            height=35
        )
    
    def _update_rect(self, instance, value):
        self.rect.pos = instance.pos
        self.rect.size = instance.size
    
    def setup_mac_paths(self):
        home = os.path.expanduser("~")
        
        if platform.system() == 'Darwin':
            possible_bases = [
                os.path.join(home, "OneDrive - Lowe's Companies Inc"),
                os.path.join(home, "Library/CloudStorage/OneDrive-LowesCompaniesInc"),
                os.path.join(home, "Lowe's Companies Inc"),
                os.path.join(home, "Documents")
            ]
        else:
            possible_bases = [
                os.path.join(home, "OneDrive - Lowe's Companies Inc"),
                os.path.join(home, "OneDrive - Lowes Companies Inc"),
                os.path.join(home, "Lowe's Companies Inc"),
                os.path.join(home, "Documents")
            ]
        
        # Define target folders with multiple name variations
        target_folder_variations = [
            ["Private Brands - Packaging Operations - Building Products"],
            ["Private Brands - Packaging Operations - Hardlines & Seasonal"],
            ["Private Brands - Packaging Operations - Home Decor",
             "Private Brands - Packaging Operations - Home DÃ©cor"]  # Try both versions
        ]
        
        base_path = None
        selected_source = "Not Found"
        actual_folders_found = []
        
        for path in possible_bases:
            if os.path.exists(path):
                temp_found = []
                
                # Try each folder variation
                for variations in target_folder_variations:
                    found_this_folder = False
                    for folder_name in variations:
                        full_path = os.path.join(path, folder_name)
                        if os.path.exists(full_path):
                            temp_found.append(full_path)
                            actual_folders_found.append(folder_name)
                            found_this_folder = True
                            break  # Found this folder, stop trying variations
                    
                    if not found_this_folder:
                        # Log which folder was not found
                        self.log_message("  [MISSING] Could not find: " + variations[0])
                
                if temp_found:
                    base_path = path
                    if "OneDrive" in path:
                        selected_source = "Local OneDrive Sync"
                    else:
                        selected_source = "Local Folder"
                    
                    self.log_message("[OK] Found base location: " + selected_source)
                    self.log_message("  Path: " + base_path)
                    self.log_message("  Folders found: " + str(len(temp_found)) + "/3")
                    for folder in actual_folders_found:
                        self.log_message("    [OK] " + folder)
                    
                    # Store the actual paths that exist
                    self.sharepoint_paths = temp_found
                    break
        
        if not base_path:
            base_path = os.path.join(home, "OneDrive - Lowe's Companies Inc")
            self.log_message("[WARNING] No folders found - using default: " + base_path)
            
            # Try default paths with both variations
            self.sharepoint_paths = []
            default_folders = [
                "Private Brands - Packaging Operations - Building Products",
                "Private Brands - Packaging Operations - Hardlines & Seasonal",
                "Private Brands - Packaging Operations - Home Decor"
            ]
            for folder in default_folders:
                self.sharepoint_paths.append(os.path.join(base_path, folder))
        
        self.default_project_tracker_path = os.path.join(
            base_path, 
            "Private Brands Packaging File Transfer - PQM Compliance reporting", 
            "Project tracker.xlsx"
        )
        
        desktop = os.path.join(home, "Desktop")
        self.output_folder = os.path.join(desktop, "Automated_Data_Processing_Output")
        os.makedirs(self.output_folder, exist_ok=True)
    
    def check_sharepoint_access(self):
        accessible_count = 0
        for path in self.sharepoint_paths:
            if os.path.exists(path):
                accessible_count += 1
        
        if accessible_count > 0:
            self.sharepoint_access_ok = True
            self.update_status("Ready - " + str(accessible_count) + " folder(s) found")
            return True
        
        self.sharepoint_access_ok = False
        self.update_status("WARNING: Target folders not found")
        return False
    
    def select_project_tracker_mac(self, instance):
        initial_dir = os.path.dirname(self.default_project_tracker_path) if os.path.exists(os.path.dirname(self.default_project_tracker_path)) else os.path.expanduser("~")
        
        if platform.system() == 'Darwin':
            try:
                applescript_cmd = 'tell application "System Events"\nactivate\nset theFile to choose file with prompt "Select Project Tracker Excel File" default location POSIX file "' + initial_dir + '" of type {"org.openxmlformats.spreadsheetml.sheet", "com.microsoft.excel.xls"}\nreturn POSIX path of theFile\nend tell'
                
                result = subprocess.run(
                    ['osascript', '-e', applescript_cmd],
                    capture_output=True,
                    text=True,
                    timeout=300
                )
                
                if result.returncode == 0 and result.stdout.strip():
                    file_path = result.stdout.strip()
                    self.project_tracker_path = file_path
                    filename = os.path.basename(file_path)
                    self.tracker_status_label.text = "Selected: " + filename
                    self.tracker_status_label.color = (0.5, 1, 0.5, 1)
                    self.apply_btn.disabled = False
                    self.log_message("Project tracker selected: " + filename)
                    return
                else:
                    self.tracker_status_label.text = "No file selected"
                    self.tracker_status_label.color = (1, 0.6, 0.6, 1)
                    return
            except Exception as e:
                self.log_message("AppleScript failed, using fallback: " + str(e))
        
        try:
            import tkinter as tk
            from tkinter import filedialog
            
            root = tk.Tk()
            root.withdraw()
            root.wm_attributes('-topmost', True)
            
            file_path = filedialog.askopenfilename(
                title="Select Project Tracker Excel File",
                filetypes=[("Excel files", "*.xlsx *.xls"), ("All files", "*.*")],
                initialdir=initial_dir,
                parent=root
            )
            
            root.quit()
            root.destroy()
            
            if file_path:
                self.project_tracker_path = file_path
                filename = os.path.basename(file_path)
                self.tracker_status_label.text = "Selected: " + filename
                self.tracker_status_label.color = (0.5, 1, 0.5, 1)
                self.apply_btn.disabled = False
                self.log_message("Project tracker selected: " + filename)
            else:
                self.tracker_status_label.text = "No file selected"
                self.tracker_status_label.color = (1, 0.6, 0.6, 1)
        except Exception as e:
            self.show_popup("Error", "File selection error: " + str(e) + "\n\nTry pasting the path manually.")
    
    def on_manual_path_change(self, instance, text):
        if text and text.strip():
            file_path = text.strip()
            if os.path.exists(file_path) and file_path.lower().endswith(('.xlsx', '.xls')):
                self.project_tracker_path = file_path
                filename = os.path.basename(file_path)
                self.tracker_status_label.text = "Manual: " + filename
                self.tracker_status_label.color = (0.5, 1, 0.5, 1)
                self.apply_btn.disabled = False
                self.log_message("Manual path: " + filename)
    
    def apply_date_filter(self, instance):
        try:
            start_str = self.start_date_input.text.strip()
            end_str = self.end_date_input.text.strip()
            
            if not start_str or not end_str:
                self.show_popup("Error", "Enter both start and end dates")
                return
            
            start_date = datetime.strptime(start_str, '%Y-%m-%d').date()
            end_date = datetime.strptime(end_str, '%Y-%m-%d').date()
            
            if start_date > end_date:
                self.show_popup("Error", "Start date must be before end date")
                return
            
            if not self.sharepoint_access_ok:
                self.show_popup("Folders Not Found", 
                    "Could not find the required folders.\nPlease ensure OneDrive is synced.")
                return
            
            self.apply_btn.disabled = True
            self.run_automated_workflow(start_date, end_date)
            
        except ValueError:
            self.show_popup("Error", "Use YYYY-MM-DD format")
        except Exception as e:
            self.show_popup("Error", "Error: " + str(e))
    
    def run_automated_workflow(self, start_date, end_date):
        import threading
        
        def process():
            error_details = None
            try:
                total_start = time.time()
                self.log_message("=" * 50)
                self.log_message("STARTING AUTOMATED WORKFLOW")
                self.log_message("Date Range: " + str(start_date) + " to " + str(end_date))
                self.log_message("=" * 50)
                
                self.update_status("Processing... Please wait")
                self.update_progress(10)
                
                self.log_message("\n[STEP 1/7] Scanning production folders...")
                self.update_status("Step 1/7: Scanning folders...")
                try:
                    if not self.scan_production_folders():
                        raise Exception("No production files found in target folders")
                    self.log_message("SUCCESS: Found " + str(len(self.production_files)) + " production files")
                except Exception as e:
                    error_details = "Step 1 Failed - Scanning folders: " + str(e)
                    raise Exception(error_details)
                self.update_progress(20)
                
                self.log_message("\n[STEP 2/7] Extracting production data...")
                self.update_status("Step 2/7: Extracting data...")
                try:
                    if not self.intelligent_data_extraction():
                        raise Exception("No valid data extracted from production files")
                    self.log_message("SUCCESS: Extracted " + str(len(self.consolidated_data)) + " records")
                except Exception as e:
                    error_details = "Step 2 Failed - Data extraction: " + str(e)
                    raise Exception(error_details)
                self.update_progress(40)
                
                self.log_message("\n[STEP 3/7] Processing project tracker...")
                self.update_status("Step 3/7: Processing tracker...")
                try:
                    if not self.process_project_tracker():
                        raise Exception("Could not process tracker file: " + os.path.basename(self.project_tracker_path))
                    self.log_message("SUCCESS: Processed " + str(len(self.project_tracker_data)) + " tracker records")
                except Exception as e:
                    error_details = "Step 3 Failed - Project tracker: " + str(e)
                    raise Exception(error_details)
                self.update_progress(60)
                
                self.log_message("\n[STEP 4/7] Combining datasets...")
                self.update_status("Step 4/7: Combining data...")
                try:
                    if not self.combine_datasets():
                        raise Exception("Dataset combination failed")
                    self.log_message("SUCCESS: Combined " + str(len(self.combined_data)) + " records")
                except Exception as e:
                    error_details = "Step 4 Failed - Combining datasets: " + str(e)
                    raise Exception(error_details)
                self.update_progress(70)
                
                self.log_message("\n[STEP 5/7] Filtering by date range...")
                self.update_status("Step 5/7: Date filtering...")
                try:
                    if not self.filter_by_date_range(start_date, end_date):
                        raise Exception("Date filtering failed")
                    self.log_message("SUCCESS: " + str(len(self.combined_data)) + " records after date filter")
                except Exception as e:
                    error_details = "Step 5 Failed - Date filtering: " + str(e)
                    raise Exception(error_details)
                self.update_progress(80)
                
                self.log_message("\n[STEP 6/7] Formatting final output...")
                self.update_status("Step 6/7: Formatting...")
                try:
                    if not self.format_final_output():
                        raise Exception("Output formatting failed")
                    self.log_message("SUCCESS: Formatted " + str(len(self.final_output_data)) + " final records")
                except Exception as e:
                    error_details = "Step 6 Failed - Formatting: " + str(e)
                    raise Exception(error_details)
                self.update_progress(90)
                
                self.log_message("\n[STEP 7/7] Saving output files...")
                self.update_status("Step 7/7: Saving files...")
                try:
                    output_files = self.save_all_outputs(start_date, end_date)
                    if not output_files:
                        raise Exception("No files were saved")
                    self.log_message("SUCCESS: Saved " + str(len(output_files)) + " files")
                except Exception as e:
                    error_details = "Step 7 Failed - Saving files: " + str(e)
                    raise Exception(error_details)
                self.update_progress(100)
                
                total_time = time.time() - total_start
                
                final_count = len(self.final_output_data)
                combined_count = len(self.consolidated_data)
                
                self.log_message("\n" + "=" * 50)
                self.log_message("WORKFLOW COMPLETED SUCCESSFULLY!")
                self.log_message("Total time: " + str(round(total_time, 1)) + "s")
                self.log_message("=" * 50)
                
                success_msg = "Processing Complete!\n\n"
                success_msg += "Time: " + str(round(total_time, 1)) + "s\n"
                success_msg += "Date Range: " + str(start_date) + " to " + str(end_date) + "\n"
                success_msg += "Combined Records: " + str(combined_count) + " (ALL DATA)\n"
                success_msg += "Final Records: " + str(final_count) + "\n"
                success_msg += "Files Created: " + str(len(output_files)) + "\n\n"
                success_msg += "- Item Number & VBU: Integer format (no decimals)\n"
                success_msg += "- Printer Code: Mapped from PKG4\n"
                success_msg += "- All rows captured!\n\n"
                success_msg += "Output: Desktop/Automated_Data_Processing_Output"
                
                self.update_status("Complete!")
                self.show_success_popup(success_msg)
                
            except Exception as e:
                error_trace = traceback.format_exc()
                self.log_message("\n" + "=" * 50)
                self.log_message("ERROR OCCURRED!")
                self.log_message("Error: " + str(e))
                self.log_message("Traceback:\n" + error_trace)
                self.log_message("=" * 50)
                
                self.update_progress(0)
                self.update_status("Failed")
                
                error_msg = str(e) if error_details else "Processing failed: " + str(e)
                
                if "No production files found" in error_msg:
                    error_msg += "\n\nCheck that folders exist and contain Excel files."
                elif "tracker" in error_msg.lower():
                    error_msg += "\n\nCheck that the Project Tracker file is valid."
                elif "No valid data extracted" in error_msg:
                    error_msg += "\n\nCheck that files contain expected columns."
                
                self.show_popup("Processing Failed", error_msg)
                Clock.schedule_once(lambda dt: setattr(self.apply_btn, 'disabled', False), 0)
        
        threading.Thread(target=process, daemon=True).start()
    
    def scan_production_folders(self):
        self.log_message("Scanning for production files...")
        
        if not self.sharepoint_access_ok:
            self.log_message("ERROR: Target folders not accessible")
            return False
        
        all_files = []
        
        for sp_path in self.sharepoint_paths:
            folder_name = os.path.basename(sp_path)
            
            if not os.path.exists(sp_path):
                self.log_message("  [X] " + folder_name + " - NOT FOUND")
                continue
            
            self.log_message("  [OK] Scanning: " + folder_name)
            
            try:
                folder_file_count = 0
                for root, dirs, files in os.walk(sp_path):
                    dirs[:] = [d for d in dirs if not d.startswith('.')]
                    
                    if root.endswith("_Production Item List"):
                        excel_files = [f for f in files 
                                     if f.lower().endswith(('.xlsx', '.xls', '.xlsm')) 
                                     and not f.startswith(('~', '.', '$'))]
                        
                        for excel_file in excel_files:
                            full_path = os.path.join(root, excel_file)
                            if os.access(full_path, os.R_OK):
                                all_files.append(full_path)
                                folder_file_count += 1
                
                self.log_message("    Found " + str(folder_file_count) + " file(s)")
                
            except Exception as e:
                self.log_message("    ERROR scanning folder: " + str(e))
        
        self.production_files = all_files
        self.log_message("\nTotal files found: " + str(len(all_files)))
        
        if len(all_files) == 0:
            self.log_message("ERROR: No Excel files found")
            return False
        
        return True
    
    def intelligent_data_extraction(self):
        self.log_message("Extracting production data (optimized)...")
        
        column_patterns = {
            'Item Number': ['item #', 'item#', 'itemnumber', 'item number'],
            'VBU': ['vbu', 'v.b.u', 'vbu (if provided)', 'vertical business unit'],
            'Product Vendor Company Name': ['vendor name', 'vendor', 'supplier'],
            'Brand': ['brand'],
            'Product Name': ['item description', 'description', 'product name'],
            'SKU New/Existing': ['sku', 'sku new/existing']
        }
        
        def extract_file(file_path):
            file_name = os.path.basename(file_path)
            try:
                sheets = []
                excel_file = pd.ExcelFile(file_path, engine='openpyxl')
                
                for sheet_name in excel_file.sheet_names:
                    try:
                        df_sample = pd.read_excel(file_path, sheet_name=sheet_name, header=None, nrows=20, engine='openpyxl')
                        if df_sample.empty:
                            continue
                        
                        header_row = self.find_header_row_fast(df_sample, column_patterns)
                        if header_row is None:
                            continue
                        
                        df_full = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row, engine='openpyxl')
                        
                        if df_full.empty:
                            continue
                        
                        sheet_data = self.extract_columns_fast(df_full, file_path, column_patterns)
                        
                        if not sheet_data.empty:
                            sheets.append(sheet_data)
                            
                    except Exception as e:
                        continue
                
                if sheets:
                    combined = pd.concat(sheets, ignore_index=True)
                    combined = combined.drop_duplicates(subset=['Item Number'], keep='first')
                    
                    if 'Item Number' not in combined.columns or combined['Item Number'].isna().all():
                        return pd.DataFrame()
                    
                    combined['Item Number'] = combined['Item Number'].astype(str).str.extract(r'(\d+)', expand=False)
                    valid_items = combined['Item Number'].notna() & (combined['Item Number'] != '')
                    combined = combined[valid_items]
                    
                    valid_count = len(combined)
                    
                    if valid_count > 0:
                        self.log_message("  [OK] " + file_name + ": " + str(valid_count) + " records")
                        return combined
                
                return pd.DataFrame()
            except Exception as e:
                self.log_message("  [X] " + file_name + ": ERROR - " + str(e))
                return pd.DataFrame()
        
        max_workers = min(8, os.cpu_count() or 4)
        self.log_message("Using " + str(max_workers) + " parallel workers...")
        
        all_data = []
        total_files = len(self.production_files)
        completed = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(extract_file, f): f for f in self.production_files}
            
            for future in as_completed(futures):
                result = future.result()
                if not result.empty:
                    all_data.append(result)
                
                completed += 1
                if completed % 10 == 0 or completed == total_files:
                    progress = 20 + int((completed / total_files) * 20)
                    self.update_progress(progress)
                    self.log_message("  Progress: " + str(completed) + "/" + str(total_files) + " files processed")
        
        if all_data:
            self.consolidated_data = pd.concat(all_data, ignore_index=True)
            self.consolidated_data = self.consolidated_data.drop_duplicates(subset=['Item Number'], keep='first')
            
            self.consolidated_data['Item Number'] = self.consolidated_data['Item Number'].astype(str).str.extract(r'(\d+)', expand=False)
            self.consolidated_data = self.consolidated_data[self.consolidated_data['Item Number'].notna() & (self.consolidated_data['Item Number'] != '')]
            self.consolidated_data['Item Number'] = self.consolidated_data['Item Number'].str.replace('.0', '', regex=False)
            self.consolidated_data = self.consolidated_data[self.consolidated_data['Item Number'] != '0']
            
            if 'VBU' in self.consolidated_data.columns:
                self.consolidated_data['VBU'] = self.consolidated_data['VBU'].astype(str).str.strip()
                self.consolidated_data['VBU'] = self.consolidated_data['VBU'].str.extract(r'(\d+)', expand=False).fillna('')
                self.consolidated_data['VBU'] = self.consolidated_data['VBU'].str.replace('.0', '', regex=False)
                self.consolidated_data['VBU'] = self.consolidated_data['VBU'].replace(['0', 'nan'], '')
                
                vbu_count = (self.consolidated_data['VBU'] != '').sum()
                self.log_message("  VBU data: " + str(vbu_count) + " records have VBU values")
            else:
                self.log_message("  WARNING: VBU column not found")
            
            self.log_message("\nTOTAL: " + str(len(self.consolidated_data)) + " valid records extracted (ALL rows captured)")
            
            if len(self.consolidated_data) == 0:
                self.log_message("ERROR: No valid records after cleaning")
                return False
            
            return True
        
        self.log_message("ERROR: No data extracted from any files")
        return False
    
    def find_header_row_fast(self, df_sample, column_patterns):
        best_row = None
        best_score = 0
        
        for row_idx in range(min(15, len(df_sample))):
            headers = df_sample.iloc[row_idx].astype(str).str.lower().str.strip()
            score = 0
            
            for target, patterns in column_patterns.items():
                for header in headers:
                    if header == 'nan' or not header:
                        continue
                    clean_header = re.sub(r'[^a-z0-9]', '', header)
                    for pattern in patterns:
                        clean_pattern = re.sub(r'[^a-z0-9]', '', pattern)
                        if clean_pattern in clean_header:
                            score += 1
                            break
                    if score > best_score:
                        break
            
            if score > best_score:
                best_score = score
                best_row = row_idx
            
            if score >= 3:
                return best_row
        
        return best_row if best_score >= 2 else None
    
    def extract_columns_fast(self, df, file_path, column_patterns):
        try:
            if df.empty:
                return pd.DataFrame()
            
            extracted = pd.DataFrame()
            cols_lower = [str(col).lower() for col in df.columns]
            
            for target in self.target_columns:
                found = False
                if target in column_patterns:
                    patterns = column_patterns[target]
                    for col_idx, col_name in enumerate(cols_lower):
                        clean_col = re.sub(r'[^a-z0-9]', '', col_name)
                        for pattern in patterns:
                            clean_pattern = re.sub(r'[^a-z0-9]', '', pattern)
                            if clean_pattern in clean_col:
                                extracted[target] = df.iloc[:, col_idx].astype(str).str.strip()
                                found = True
                                break
                        if found:
                            break
                
                if not found:
                    extracted[target] = ''
            
            if 'Item Number' in extracted.columns:
                extracted['Item Number'] = extracted['Item Number'].astype(str).str.extract(r'(\d+)', expand=False)
                extracted = extracted[extracted['Item Number'].notna() & (extracted['Item Number'] != '')]
            
            if 'VBU' in extracted.columns:
                extracted['VBU'] = extracted['VBU'].astype(str).str.strip()
            
            if len(extracted) > 0:
                extracted['Source_File'] = os.path.basename(file_path)
                extracted['Source_Folder'] = os.path.basename(os.path.dirname(file_path))
            
            return extracted
        except:
            return pd.DataFrame()
    
    def process_project_tracker(self):
        try:
            if not self.project_tracker_path:
                self.log_message("ERROR: No project tracker path specified")
                return False
            
            if not os.path.exists(self.project_tracker_path):
                self.log_message("ERROR: File not found: " + self.project_tracker_path)
                return False
            
            if not os.access(self.project_tracker_path, os.R_OK):
                self.log_message("ERROR: Cannot read file: " + self.project_tracker_path)
                return False
            
            self.log_message("Processing: " + os.path.basename(self.project_tracker_path))
            
            try:
                excel_file = pd.ExcelFile(self.project_tracker_path, engine='openpyxl')
            except Exception as e:
                self.log_message("ERROR: Cannot open Excel file: " + str(e))
                return False
            
            best_result = None
            best_score = 0
            
            self.log_message("  Found " + str(len(excel_file.sheet_names)) + " sheet(s)")
            
            for sheet_name in excel_file.sheet_names:
                try:
                    df = pd.read_excel(self.project_tracker_path, sheet_name=sheet_name, engine='openpyxl')
                    result = self.process_tracker_sheet_fast(df)
                    
                    if result is not None and len(result) > best_score:
                        best_result = result
                        best_score = len(result)
                        self.log_message("  [OK] Sheet '" + sheet_name + "': " + str(len(result)) + " valid records")
                except Exception as e:
                    self.log_message("  [X] Sheet '" + sheet_name + "': " + str(e))
                    continue
            
            if best_result is not None:
                self.project_tracker_data = best_result
                
                if 'Printer Code 1 (LW Code)' in best_result.columns:
                    printer_code_count = (best_result['Printer Code 1 (LW Code)'] != '').sum()
                    self.log_message("  Printer Code: " + str(printer_code_count) + " records from PKG4")
                
                self.log_message("SUCCESS: Processed " + str(len(best_result)) + " tracker records")
                return True
            else:
                self.log_message("ERROR: No valid tracker data found")
                return False
                
        except Exception as e:
            self.log_message("ERROR processing tracker: " + str(e))
            return False
    
    def process_tracker_sheet_fast(self, df):
        try:
            cols_lower = [str(col).lower() for col in df.columns]
            
            mappings = {
                'HUGO ID': ['pkg3'],
                'File Name': ['file name', 'filename'],
                'Rounds': ['rounds'],
                'PKG1': ['pkg1'],
                'PKG4': ['pkg4'],
                'Artwork Release Date': ['releasedate', 'release date'],
                '5 Weeks After Artwork Release': ['5 weeks after artwork release'],
                'Entered into HUGO Date': ['entered into hugo date'],
                'Entered in HUGO?': ['entered in hugo?'],
                'Store Date': ['store date'],
                'Packaging Format 1': ['packaging format 1'],
                'Printer Code 1 (LW Code)': ['printer code 1 (lw code)', 'printer code 1'],
                'Printer Company Name 1': ['pacomments'],
                'Vendor e-mail 1': ['vendoremail'],
                'Printer e-mail 1': ['printeremail']
            }
            
            found = {}
            for target, patterns in mappings.items():
                for col_idx, col_name in enumerate(cols_lower):
                    clean_col = re.sub(r'[^a-z0-9]', '', col_name)
                    for pattern in patterns:
                        clean_pattern = re.sub(r'[^a-z0-9]', '', pattern)
                        if clean_pattern in clean_col:
                            found[target] = df.columns[col_idx]
                            break
                    if target in found:
                        break
            
            if 'Rounds' not in found:
                return None
            
            rounds_col = found['Rounds']
            filter_vals = ["File Release", "File Re-Release R2", "File Re-Release R3"]
            mask = df[rounds_col].isin(filter_vals)
            filtered = df[mask].copy()
            
            if len(filtered) == 0:
                return None
            
            result = pd.DataFrame(index=filtered.index)
            
            for target, source in found.items():
                if target == 'Artwork Release Date':
                    dates = filtered[source]
                    date_mask = pd.notna(dates) & (dates != "")
                    result[target] = ""
                    if date_mask.any():
                        valid = pd.to_datetime(dates[date_mask], errors='coerce')
                        formatted = valid.dt.strftime("%d/%m/%y")
                        result.loc[date_mask, target] = formatted
                else:
                    result[target] = filtered[source].fillna("")
            
            if 'PKG4' in found and 'Printer Code 1 (LW Code)' not in result.columns:
                result['Printer Code 1 (LW Code)'] = filtered[found['PKG4']].fillna("")
            elif 'PKG4' in found:
                result['Printer Code 1 (LW Code)'] = filtered[found['PKG4']].fillna("")
            
            rounds_upper = filtered[found['Rounds']].astype(str).str.upper()
            result['Re-Release Status'] = rounds_upper.str.contains('R2|R3', na=False, regex=True).map({True: 'Yes', False: ''})
            
            return result
        except:
            return None
    
    def combine_datasets(self):
        try:
            if self.consolidated_data.empty or self.project_tracker_data.empty:
                return False
            
            step1 = self.consolidated_data.copy()
            step2 = self.project_tracker_data.copy()
            
            step1['Merge_Key'] = step1['Item Number'].astype(str).str.extract(r'(\d+)', expand=False).fillna('')
            step2['Merge_Key'] = step2['PKG1'].astype(str).str.extract(r'(\d+)', expand=False).fillna('')
            
            step1 = step1[step1['Merge_Key'] != '']
            step2 = step2[step2['Merge_Key'] != '']
            
            combined = pd.merge(step1, step2, on='Merge_Key', how='outer', indicator=True)
            combined['Data_Source'] = combined['_merge'].map({
                'both': 'Step1 + Step2',
                'left_only': 'Step1 Only',
                'right_only': 'Step2 Only'
            })
            
            combined = combined.drop(columns=['_merge'])
            
            self.combined_data = combined
            self.log_message("Combined: " + str(len(combined)) + " records")
            return True
        except Exception as e:
            self.log_message("Combination error: " + str(e))
            return False
    
    def filter_by_date_range(self, start_date, end_date):
        try:
            self.log_message("Filtering dates: " + str(start_date) + " to " + str(end_date))
            
            if self.combined_data.empty:
                return False
            
            date_col = None
            for col in self.combined_data.columns:
                col_lower = col.lower()
                if 'artwork' in col_lower and 'release' in col_lower and 'date' in col_lower:
                    date_col = col
                    break
            
            if not date_col:
                for col in self.combined_data.columns:
                    col_lower = col.lower()
                    if 'release' in col_lower and 'date' in col_lower:
                        date_col = col
                        break
            
            if not date_col:
                self.log_message("No date column found - skipping date filter")
                return True
            
            filtered = self.combined_data.copy()
            
            filtered['Parsed_Date'] = pd.to_datetime(filtered[date_col], format='%d/%m/%y', errors='coerce')
            
            mask_null = filtered['Parsed_Date'].isna()
            if mask_null.any():
                filtered.loc[mask_null, 'Parsed_Date'] = pd.to_datetime(
                    filtered.loc[mask_null, date_col], 
                    format='%d/%m/%Y', 
                    errors='coerce'
                )
            
            mask = (
                filtered['Parsed_Date'].notna() & 
                (filtered['Parsed_Date'].dt.date >= start_date) & 
                (filtered['Parsed_Date'].dt.date <= end_date)
            )
            
            filtered = filtered[mask].drop(columns=['Parsed_Date'])
            
            self.combined_data = filtered
            self.log_message("After filtering: " + str(len(filtered)) + " records")
            return True
        except Exception as e:
            self.log_message("Date filter error: " + str(e))
            return True
    
    def format_final_output(self):
        try:
            if self.combined_data.empty:
                self.final_output_data = pd.DataFrame(columns=self.final_columns)
                return True
            
            final_df = pd.DataFrame()
            
            mapping = {
                'HUGO ID': 'HUGO ID',
                'Product Vendor Company Name': 'Product Vendor Company Name',
                'Item Number': 'Item Number',
                'VBU': 'VBU',
                'Product Name': 'Product Name',
                'Brand': 'Brand',
                'SKU': 'SKU New/Existing',
                'Artwork Release Date': 'Artwork Release Date',
                '5 Weeks After Artwork Release': '5 Weeks After Artwork Release',
                'Entered into HUGO Date': 'Entered into HUGO Date',
                'Entered in HUGO?': 'Entered in HUGO?',
                'Store Date': 'Store Date',
                'Re-Release Status': 'Re-Release Status',
                'Packaging Format 1': 'Packaging Format 1',
                'Printer Company Name 1': 'Printer Company Name 1',
                'Vendor e-mail 1': 'Vendor e-mail 1',
                'Printer e-mail 1': 'Printer e-mail 1',
                'Printer Code 1 (LW Code)': 'Printer Code 1 (LW Code)',
                'File Name': 'File Name'
            }
            
            for final_col in self.final_columns:
                if final_col in mapping:
                    source = mapping[final_col]
                    if source in self.combined_data.columns:
                        final_df[final_col] = self.combined_data[source]
                    else:
                        final_df[final_col] = ''
                else:
                    final_df[final_col] = ''
            
            final_df = final_df.fillna('')
            
            if len(final_df) > 0:
                valid_mask = (final_df['Item Number'].astype(str).str.strip() != '')
                final_df = final_df[valid_mask]
            
            self.final_output_data = final_df
            self.log_message("Final output: " + str(len(final_df)) + " records")
            return True
        except Exception as e:
            self.log_message("Format error: " + str(e))
            return False
    
    def save_all_outputs(self, start_date, end_date):
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            date_range = start_date.strftime('%Y%m%d') + "_to_" + end_date.strftime('%Y%m%d')
            
            files = []
            
            if not self.consolidated_data.empty:
                combined_file = os.path.join(self.output_folder, "Combined_Data_" + date_range + "_" + timestamp + ".xlsx")
                
                combined_export = self.consolidated_data.copy()
                
                if 'Item Number' in combined_export.columns:
                    combined_export['Item Number'] = pd.to_numeric(combined_export['Item Number'], errors='coerce').fillna(0).astype('int64')
                
                if 'VBU' in combined_export.columns:
                    vbu_numeric = pd.to_numeric(combined_export['VBU'], errors='coerce')
                    combined_export['VBU'] = vbu_numeric.where(vbu_numeric.notna(), None)
                
                with pd.ExcelWriter(combined_file, engine='xlsxwriter') as writer:
                    combined_export.to_excel(writer, sheet_name='Combined Data', index=False)
                    
                    workbook = writer.book
                    worksheet = writer.sheets['Combined Data']
                    
                    integer_format = workbook.add_format({'num_format': '0', 'align': 'left'})
                    
                    for col_num, col_name in enumerate(combined_export.columns):
                        if col_name == 'Item Number':
                            worksheet.set_column(col_num, col_num, 15, integer_format)
                        elif col_name == 'VBU':
                            worksheet.set_column(col_num, col_num, 10, integer_format)
                
                files.append(combined_file)
                self.log_message("Saved: " + os.path.basename(combined_file) + " (" + str(len(combined_export)) + " rows)")
            
            final_file = os.path.join(self.output_folder, "Final_Output_" + date_range + "_" + timestamp + ".xlsx")
            
            final_export = self.final_output_data.copy()
            
            if 'Item Number' in final_export.columns:
                final_export['Item Number'] = pd.to_numeric(final_export['Item Number'], errors='coerce').fillna(0).astype('int64')
            
            if 'VBU' in final_export.columns:
                vbu_numeric = pd.to_numeric(final_export['VBU'], errors='coerce')
                final_export['VBU'] = vbu_numeric.where(vbu_numeric.notna(), None)
            
            with pd.ExcelWriter(final_file, engine='xlsxwriter') as writer:
                final_export.to_excel(writer, sheet_name='Final Data', index=False)
                
                workbook = writer.book
                worksheet = writer.sheets['Final Data']
                
                integer_format = workbook.add_format({'num_format': '0', 'align': 'left'})
                
                for col_num, col_name in enumerate(final_export.columns):
                    if col_name in ['Item Number', 'VBU']:
                        worksheet.set_column(col_num, col_num, 15, integer_format)
            
            files.append(final_file)
            self.log_message("Saved: " + os.path.basename(final_file) + " (" + str(len(final_export)) + " rows)")
            
            return files
        except Exception as e:
            self.log_message("Save error: " + str(e))
            return []
    
    def log_message(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.processing_logs.append("[" + timestamp + "] " + message)
        print("[" + timestamp + "] " + message)
    
    def update_status(self, message):
        Clock.schedule_once(lambda dt: setattr(self.status_label, 'text', "Status: " + message), 0)
    
    def update_progress(self, value):
        Clock.schedule_once(lambda dt: setattr(self.progress_bar, 'value', value), 0)
    
    def show_popup(self, title, message):
        def _show_popup(dt):
            content = BoxLayout(orientation='vertical', padding=10, spacing=10)
            
            label = Label(text=message, halign="center", valign="middle")
            label.bind(size=label.setter('text_size'))
            
            btn = Button(
                text="OK",
                size_hint_y=None,
                height=50,
                background_color=(0.2, 0.6, 0.9, 1)
            )
            
            popup = Popup(title=title, content=content, size_hint=(0.8, 0.6))
            btn.bind(on_press=popup.dismiss)
            
            content.add_widget(label)
            content.add_widget(btn)
            popup.open()
        
        Clock.schedule_once(_show_popup, 0)
    
    def show_success_popup(self, message):
        def _show_success(dt):
            self.show_popup("Success!", message)
            self.open_folder_btn.disabled = False
        
        Clock.schedule_once(_show_success, 0)
    
    def open_output_folder(self, instance):
        try:
            if platform.system() == 'Darwin':
                subprocess.run(['open', self.output_folder])
            elif platform.system() == 'Windows':
                os.startfile(self.output_folder)
            else:
                subprocess.run(['xdg-open', self.output_folder])
        except Exception as e:
            self.show_popup("Error", "Could not open folder: " + str(e))


def main():
    if sys.version_info < (3, 8):
        print("Python 3.8+ required. Current: " + sys.version)
        return
    
    if platform.system() != 'Darwin':
        print("NOTE: Optimized for macOS but will run on Windows")
    
    print("Starting Mac Data Processor...")
    print("=" * 50)
    
    try:
        app = MacDataProcessor()
        app.run()
    except Exception as e:
        print("Error: " + str(e))
        traceback.print_exc()


if __name__ == "__main__":
    main()
